---
title: "Homework 5"
author: Yike Zhao
output: github_document
---

This is my solution to HW5.

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



## Problem 2

import one dataset 

```{r}
data_1 = read_csv("lda_data/con_01.csv")
```

Iterate over file names and tidy the result dataframe

```{r, error = TRUE}
path_df = 
  tibble(
    path = list.files("lda_data"),
  ) %>% 
  mutate(
    path = str_c("lda_data/", path)
  ) 

obs_df =
  path_df %>% 
  mutate(
    obs = map(.x = path, ~read_csv(.x))
  ) %>% 
  unnest(obs) %>% 
  mutate(
    path = str_replace(path, "lda_data/", ""),
    path = str_replace(path, ".csv", "")
  ) %>% 
  tibble::rowid_to_column("index") %>% 
  separate(path, c("arms", "id")) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observations"
  )
```

Make a spaghetti plot showing observations on each subject over time.

```{r}
obs_df %>% 
  ggplot(aes(x = week, y = observations, color = arms, group = index)) + 
  geom_smooth(se = FALSE) +
  labs(
    title = "Observations of Each Object Over 8 Weeks",
    x = "Week",
    y = "Observations",
    caption ="Data from the lda package"
  ) 
```

From the plot we can see the observation value tend to be higher in the experiment groups than the control groups. While the level of the observation values are more stable across the 8 weeks for objects in the control group, an increasing trend is observed in the objects of the experiment group.



## Problem 3

Write the function that performs the hypothesis test

```{r}
sample = function(n, mean, sd){
  samp_data = tibble(
  samp = rnorm(n, mean, sd)
  )
  samp_result = nest(samp_data) %>%
  mutate(
  t_test = map(.x = data, ~t.test(x = .x,mu=0, alternative = 'two.sided', paired = FALSE, conf.level = 0.95)),
  tidy_ttest = map(.x = t_test, ~broom::tidy(.x))
  ) %>% 
  unnest(tidy_ttest) %>% 
  select(c(estimate, p.value))
  
  return(samp_result)
}
```

Simulate for 6 different means

```{r}
sim_results = 
  tibble(miu = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = miu, ~rerun(5000, sample(n = 30, mean = .x, sd = 5))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. 

```{r}
plot1_df = 
  sim_results %>% 
  group_by(miu) %>% 
  summarize(
    total = n(),
    rejected = sum(p.value < 0.05)
  )
```


```{r}
plot1_df %>% 
  ggplot(aes(x = miu, y = rejected/total)) + 
  geom_smooth(se = FALSE) +
  labs(
    title = "Power of Tests with Different Mean",
    x = "Distribution Mean (u)",
    y = "Proportions of Null Rejected (Power)"
  ) +
  scale_x_continuous(
    breaks = c(1,2,3,4,5,6), 
    labels = c("1", "12", "3", "4", "5", "6"))
```

The effect size is in direct proportion to power. 


Make a plot showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.

```{r}
plot2_df = 
  sim_results %>% 
  group_by(miu) %>% 
  summarize(
    average_miu = sum(estimate)/n()
  )

plot3_df = 
  sim_results %>% 
  filter(p.value < 0.05) %>% 
  group_by(miu) %>% 
  summarize(
    average_miu = sum(estimate)/n()
  )
```

```{r}
ggplot(plot2_df, aes(x = miu, y = average_miu)) + 
  geom_smooth(se = FALSE)+
  labs(
    title = "Average Estimate of Tests with Different Mean",
    x = "Distribution Mean (u)",
    y = "Average Estimate of Miu"
  ) +
  scale_x_continuous(
    breaks = c(1,2,3,4,5,6), 
    labels = c("1", "12", "3", "4", "5", "6"))
```


```{r}
ggplot(plot3_df, aes(x = miu, y = average_miu)) + 
  geom_smooth(se = FALSE) +
  labs(
    title = "Average Estimate of Tests That the Null Was Rejected",
    x = "Distribution Mean (u)",
    y = "Average Estimate of Miu"
  ) +
  scale_x_continuous(
    breaks = c(1,2,3,4,5,6), 
    labels = c("1", "12", "3", "4", "5", "6"))
```

The sample average of μ̂  across tests for which the null is rejected is not similar to the true value of μ. Since the unrejected tests tend to be lower than the true miu.

